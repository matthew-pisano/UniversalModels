import pytest

from universalmodels.mock_tokenizer import MockTokenizer


def is_int_list(int_list: list[int]):
    for int_value in int_list:
        if not isinstance(int_value, int):
            return False
    return True


@pytest.fixture
def mock_tokenizer():
    return MockTokenizer("foo")


@pytest.fixture
def decoded_strings():
    return {
        "empty": "",
        "ascii": "hello \n\t\rthere",
        "unicode": "üòÄüòÄü§ìü§ì‚ü®–±‚ü©, ‚ü®–≤‚ü©, ‚ü®–≥‚ü©, ‚ü®–¥‚ü©, ‚ü®–∂‚ü©, ‚ü®–∑‚ü©, ‚ü®–∫‚ü©, ‚ü®–ª‚ü©, ‚ü®–º‚ü©, ‚ü®–Ω‚ü©, Ê∞¥ (Ê∞µ) 'water'  ‰πü /*lAj î/  /*C…ô.lraj/  drje  ch√≠ [ à Ç ∞iÃå]  ci4 [ts ∞iÀêÀ©]  chi [t…ïi] È¶≥  'gallop'  È¶¨ 'horse'  /*[l]raj/"
    }


def test_encode_empty(mock_tokenizer, decoded_strings):
    tokens = mock_tokenizer.encode(decoded_strings["empty"])
    assert is_int_list(tokens)


def test_encode_ascii(mock_tokenizer, decoded_strings):
    tokens = mock_tokenizer.encode(decoded_strings["ascii"])
    assert is_int_list(tokens)


def test_encode_unicode(mock_tokenizer, decoded_strings):
    tokens = mock_tokenizer.encode(decoded_strings["unicode"])
    assert is_int_list(tokens)


def test_decode_empty(mock_tokenizer, decoded_strings):
    tokens = mock_tokenizer.encode(decoded_strings["empty"])
    decoded = mock_tokenizer.decode(tokens)
    assert decoded == decoded_strings["empty"]


def test_decode_ascii(mock_tokenizer, decoded_strings):
    tokens = mock_tokenizer.encode(decoded_strings["ascii"])
    decoded = mock_tokenizer.decode(tokens)
    assert decoded == decoded_strings["ascii"]


def test_decode_unicode(mock_tokenizer, decoded_strings):
    tokens = mock_tokenizer.encode(decoded_strings["unicode"])
    decoded = mock_tokenizer.decode(tokens)
    assert decoded == decoded_strings["unicode"]
